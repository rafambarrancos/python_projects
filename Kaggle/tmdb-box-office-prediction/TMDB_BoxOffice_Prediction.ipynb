{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rafael/anaconda/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Import libraries necessary for this project\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time\n",
    "from IPython.display import display # Allows the use of display() for DataFrames\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss\n",
    "import timeit\n",
    "from sklearn.decomposition import PCA\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import de Datasets\n",
    "dt_train = pd.read_csv(\"train.csv\")\n",
    "dt_test = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>belongs_to_collection</th>\n",
       "      <th>budget</th>\n",
       "      <th>genres</th>\n",
       "      <th>homepage</th>\n",
       "      <th>imdb_id</th>\n",
       "      <th>original_language</th>\n",
       "      <th>original_title</th>\n",
       "      <th>overview</th>\n",
       "      <th>popularity</th>\n",
       "      <th>...</th>\n",
       "      <th>release_date</th>\n",
       "      <th>runtime</th>\n",
       "      <th>spoken_languages</th>\n",
       "      <th>status</th>\n",
       "      <th>tagline</th>\n",
       "      <th>title</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>cast</th>\n",
       "      <th>crew</th>\n",
       "      <th>revenue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[{'id': 313576, 'name': 'Hot Tub Time Machine ...</td>\n",
       "      <td>14000000</td>\n",
       "      <td>[{'id': 35, 'name': 'Comedy'}]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tt2637294</td>\n",
       "      <td>en</td>\n",
       "      <td>Hot Tub Time Machine 2</td>\n",
       "      <td>When Lou, who has become the \"father of the In...</td>\n",
       "      <td>6.575393</td>\n",
       "      <td>...</td>\n",
       "      <td>2/20/15</td>\n",
       "      <td>93.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>The Laws of Space and Time are About to be Vio...</td>\n",
       "      <td>Hot Tub Time Machine 2</td>\n",
       "      <td>[{'id': 4379, 'name': 'time travel'}, {'id': 9...</td>\n",
       "      <td>[{'cast_id': 4, 'character': 'Lou', 'credit_id...</td>\n",
       "      <td>[{'credit_id': '59ac067c92514107af02c8c8', 'de...</td>\n",
       "      <td>12314651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[{'id': 107674, 'name': 'The Princess Diaries ...</td>\n",
       "      <td>40000000</td>\n",
       "      <td>[{'id': 35, 'name': 'Comedy'}, {'id': 18, 'nam...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tt0368933</td>\n",
       "      <td>en</td>\n",
       "      <td>The Princess Diaries 2: Royal Engagement</td>\n",
       "      <td>Mia Thermopolis is now a college graduate and ...</td>\n",
       "      <td>8.248895</td>\n",
       "      <td>...</td>\n",
       "      <td>8/6/04</td>\n",
       "      <td>113.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>It can take a lifetime to find true love; she'...</td>\n",
       "      <td>The Princess Diaries 2: Royal Engagement</td>\n",
       "      <td>[{'id': 2505, 'name': 'coronation'}, {'id': 42...</td>\n",
       "      <td>[{'cast_id': 1, 'character': 'Mia Thermopolis'...</td>\n",
       "      <td>[{'credit_id': '52fe43fe9251416c7502563d', 'de...</td>\n",
       "      <td>95149435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3300000</td>\n",
       "      <td>[{'id': 18, 'name': 'Drama'}]</td>\n",
       "      <td>http://sonyclassics.com/whiplash/</td>\n",
       "      <td>tt2582802</td>\n",
       "      <td>en</td>\n",
       "      <td>Whiplash</td>\n",
       "      <td>Under the direction of a ruthless instructor, ...</td>\n",
       "      <td>64.299990</td>\n",
       "      <td>...</td>\n",
       "      <td>10/10/14</td>\n",
       "      <td>105.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>The road to greatness can take you to the edge.</td>\n",
       "      <td>Whiplash</td>\n",
       "      <td>[{'id': 1416, 'name': 'jazz'}, {'id': 1523, 'n...</td>\n",
       "      <td>[{'cast_id': 5, 'character': 'Andrew Neimann',...</td>\n",
       "      <td>[{'credit_id': '54d5356ec3a3683ba0000039', 'de...</td>\n",
       "      <td>13092000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1200000</td>\n",
       "      <td>[{'id': 53, 'name': 'Thriller'}, {'id': 18, 'n...</td>\n",
       "      <td>http://kahaanithefilm.com/</td>\n",
       "      <td>tt1821480</td>\n",
       "      <td>hi</td>\n",
       "      <td>Kahaani</td>\n",
       "      <td>Vidya Bagchi (Vidya Balan) arrives in Kolkata ...</td>\n",
       "      <td>3.174936</td>\n",
       "      <td>...</td>\n",
       "      <td>3/9/12</td>\n",
       "      <td>122.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}, {'iso...</td>\n",
       "      <td>Released</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kahaani</td>\n",
       "      <td>[{'id': 10092, 'name': 'mystery'}, {'id': 1054...</td>\n",
       "      <td>[{'cast_id': 1, 'character': 'Vidya Bagchi', '...</td>\n",
       "      <td>[{'credit_id': '52fe48779251416c9108d6eb', 'de...</td>\n",
       "      <td>16000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>[{'id': 28, 'name': 'Action'}, {'id': 53, 'nam...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tt1380152</td>\n",
       "      <td>ko</td>\n",
       "      <td>마린보이</td>\n",
       "      <td>Marine Boy is the story of a former national s...</td>\n",
       "      <td>1.148070</td>\n",
       "      <td>...</td>\n",
       "      <td>2/5/09</td>\n",
       "      <td>118.0</td>\n",
       "      <td>[{'iso_639_1': 'ko', 'name': '한국어/조선말'}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Marine Boy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'cast_id': 3, 'character': 'Chun-soo', 'cred...</td>\n",
       "      <td>[{'credit_id': '52fe464b9251416c75073b43', 'de...</td>\n",
       "      <td>3923970</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                              belongs_to_collection    budget  \\\n",
       "0   1  [{'id': 313576, 'name': 'Hot Tub Time Machine ...  14000000   \n",
       "1   2  [{'id': 107674, 'name': 'The Princess Diaries ...  40000000   \n",
       "2   3                                                NaN   3300000   \n",
       "3   4                                                NaN   1200000   \n",
       "4   5                                                NaN         0   \n",
       "\n",
       "                                              genres  \\\n",
       "0                     [{'id': 35, 'name': 'Comedy'}]   \n",
       "1  [{'id': 35, 'name': 'Comedy'}, {'id': 18, 'nam...   \n",
       "2                      [{'id': 18, 'name': 'Drama'}]   \n",
       "3  [{'id': 53, 'name': 'Thriller'}, {'id': 18, 'n...   \n",
       "4  [{'id': 28, 'name': 'Action'}, {'id': 53, 'nam...   \n",
       "\n",
       "                            homepage    imdb_id original_language  \\\n",
       "0                                NaN  tt2637294                en   \n",
       "1                                NaN  tt0368933                en   \n",
       "2  http://sonyclassics.com/whiplash/  tt2582802                en   \n",
       "3         http://kahaanithefilm.com/  tt1821480                hi   \n",
       "4                                NaN  tt1380152                ko   \n",
       "\n",
       "                             original_title  \\\n",
       "0                    Hot Tub Time Machine 2   \n",
       "1  The Princess Diaries 2: Royal Engagement   \n",
       "2                                  Whiplash   \n",
       "3                                   Kahaani   \n",
       "4                                      마린보이   \n",
       "\n",
       "                                            overview  popularity  ...  \\\n",
       "0  When Lou, who has become the \"father of the In...    6.575393  ...   \n",
       "1  Mia Thermopolis is now a college graduate and ...    8.248895  ...   \n",
       "2  Under the direction of a ruthless instructor, ...   64.299990  ...   \n",
       "3  Vidya Bagchi (Vidya Balan) arrives in Kolkata ...    3.174936  ...   \n",
       "4  Marine Boy is the story of a former national s...    1.148070  ...   \n",
       "\n",
       "  release_date runtime                                   spoken_languages  \\\n",
       "0      2/20/15    93.0           [{'iso_639_1': 'en', 'name': 'English'}]   \n",
       "1       8/6/04   113.0           [{'iso_639_1': 'en', 'name': 'English'}]   \n",
       "2     10/10/14   105.0           [{'iso_639_1': 'en', 'name': 'English'}]   \n",
       "3       3/9/12   122.0  [{'iso_639_1': 'en', 'name': 'English'}, {'iso...   \n",
       "4       2/5/09   118.0           [{'iso_639_1': 'ko', 'name': '한국어/조선말'}]   \n",
       "\n",
       "     status                                            tagline  \\\n",
       "0  Released  The Laws of Space and Time are About to be Vio...   \n",
       "1  Released  It can take a lifetime to find true love; she'...   \n",
       "2  Released    The road to greatness can take you to the edge.   \n",
       "3  Released                                                NaN   \n",
       "4  Released                                                NaN   \n",
       "\n",
       "                                      title  \\\n",
       "0                    Hot Tub Time Machine 2   \n",
       "1  The Princess Diaries 2: Royal Engagement   \n",
       "2                                  Whiplash   \n",
       "3                                   Kahaani   \n",
       "4                                Marine Boy   \n",
       "\n",
       "                                            Keywords  \\\n",
       "0  [{'id': 4379, 'name': 'time travel'}, {'id': 9...   \n",
       "1  [{'id': 2505, 'name': 'coronation'}, {'id': 42...   \n",
       "2  [{'id': 1416, 'name': 'jazz'}, {'id': 1523, 'n...   \n",
       "3  [{'id': 10092, 'name': 'mystery'}, {'id': 1054...   \n",
       "4                                                NaN   \n",
       "\n",
       "                                                cast  \\\n",
       "0  [{'cast_id': 4, 'character': 'Lou', 'credit_id...   \n",
       "1  [{'cast_id': 1, 'character': 'Mia Thermopolis'...   \n",
       "2  [{'cast_id': 5, 'character': 'Andrew Neimann',...   \n",
       "3  [{'cast_id': 1, 'character': 'Vidya Bagchi', '...   \n",
       "4  [{'cast_id': 3, 'character': 'Chun-soo', 'cred...   \n",
       "\n",
       "                                                crew   revenue  \n",
       "0  [{'credit_id': '59ac067c92514107af02c8c8', 'de...  12314651  \n",
       "1  [{'credit_id': '52fe43fe9251416c7502563d', 'de...  95149435  \n",
       "2  [{'credit_id': '54d5356ec3a3683ba0000039', 'de...  13092000  \n",
       "3  [{'credit_id': '52fe48779251416c9108d6eb', 'de...  16000000  \n",
       "4  [{'credit_id': '52fe464b9251416c75073b43', 'de...   3923970  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(dt_train.head(n=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[{'id': 313576, 'name': 'Hot Tub Time Machine Collection', 'poster_path': '/iEhb00TGPucF0b4joM1ieyY026U.jpg', 'backdrop_path': '/noeTVcgpBiD48fDjFVic1Vz7ope.jpg'}]\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_train['belongs_to_collection'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3000 entries, 0 to 2999\n",
      "Data columns (total 23 columns):\n",
      "id                       3000 non-null int64\n",
      "belongs_to_collection    604 non-null object\n",
      "budget                   3000 non-null int64\n",
      "genres                   2993 non-null object\n",
      "homepage                 946 non-null object\n",
      "imdb_id                  3000 non-null object\n",
      "original_language        3000 non-null object\n",
      "original_title           3000 non-null object\n",
      "overview                 2992 non-null object\n",
      "popularity               3000 non-null float64\n",
      "poster_path              2999 non-null object\n",
      "production_companies     2844 non-null object\n",
      "production_countries     2945 non-null object\n",
      "release_date             3000 non-null object\n",
      "runtime                  2998 non-null float64\n",
      "spoken_languages         2980 non-null object\n",
      "status                   3000 non-null object\n",
      "tagline                  2403 non-null object\n",
      "title                    3000 non-null object\n",
      "Keywords                 2724 non-null object\n",
      "cast                     2987 non-null object\n",
      "crew                     2984 non-null object\n",
      "revenue                  3000 non-null int64\n",
      "dtypes: float64(2), int64(3), object(18)\n",
      "memory usage: 539.1+ KB\n"
     ]
    }
   ],
   "source": [
    "dt_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import ast, math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "collection = dt_train['belongs_to_collection']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coll_list = []\n",
    "for item in dt_train['belongs_to_collection']:\n",
    "    try:\n",
    "        if math.isnan(item):\n",
    "            coll_list.append({})\n",
    "    except:\n",
    "        coll_list.append(ast.literal_eval(item.replace('[','').replace(']','')))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Budget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "budget = pd.DataFrame(dt_train['budget'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaler_bu = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rafael/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/data.py:323: DataConversionWarning: Data with input dtype int64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "budget_sc = pd.DataFrame(scaler_bu.fit_transform(budget)).rename(index=str, columns={0: \"budget\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "budget_sc = budget_sc.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2.411e+03, 3.630e+02, 1.230e+02, 5.500e+01, 2.000e+01, 1.700e+01,\n",
       "        7.000e+00, 3.000e+00, 0.000e+00, 1.000e+00]),\n",
       " array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAD8CAYAAACRkhiPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a1d87c1d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(budget_sc['budget'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### original_language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "original_language = dt_train['original_language']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "original_language_dummies = pd.get_dummies(original_language)[['en','fr','ru','es','hi']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Popularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "popularity = pd.DataFrame(dt_train['popularity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaler_pop = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "popularity_sc = pd.DataFrame(scaler_pop.fit_transform(popularity)).rename(index=str, columns={0: \"pop\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Production companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "companies = dt_train['production_companies']\n",
    "companies = companies.fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_companies = []\n",
    "for obs in companies:\n",
    "    if obs!='':\n",
    "        item = ast.literal_eval(obs.replace('[','').replace(']',''))\n",
    "        if type(item)==dict:\n",
    "            all_companies.append(item['name'])\n",
    "        else:\n",
    "            for c in item:\n",
    "                all_companies.append(c['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_companies_dt = pd.Series(all_companies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_col(name,name_col):\n",
    "    dt_train[name.lower()] = dt_train[name_col].str.contains(name, regex=False)\n",
    "    dt_train[name.lower()] = dt_train[name.lower()].apply(lambda x: 1 if x ==True else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for item in all_companies_dt.value_counts().index[0:10]:\n",
    "    create_col(item,'production_companies')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a=[]\n",
    "for item in all_companies_dt.value_counts().index[0:10]:\n",
    "    a.append(item.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Production countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "countries = dt_train['production_countries']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "countries = countries.fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_countries = []\n",
    "for obs in countries:\n",
    "    if obs!='':\n",
    "        item = ast.literal_eval(obs.replace('[','').replace(']',''))\n",
    "        if type(item)==dict:\n",
    "            all_countries.append(item['name'])\n",
    "        else:\n",
    "            for c in item:\n",
    "                all_countries.append(c['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_countries_dt = pd.Series(all_countries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "United States of America    2282\n",
       "United Kingdom               380\n",
       "France                       222\n",
       "Germany                      167\n",
       "Canada                       120\n",
       "India                         81\n",
       "Italy                         64\n",
       "Japan                         61\n",
       "Australia                     61\n",
       "Russia                        58\n",
       "Spain                         54\n",
       "China                         42\n",
       "Hong Kong                     42\n",
       "Ireland                       23\n",
       "Belgium                       23\n",
       "South Korea                   22\n",
       "Mexico                        19\n",
       "Sweden                        18\n",
       "New Zealand                   17\n",
       "Netherlands                   15\n",
       "Czech Republic                14\n",
       "Denmark                       13\n",
       "Brazil                        12\n",
       "Luxembourg                    10\n",
       "South Africa                  10\n",
       "United Arab Emirates           9\n",
       "Hungary                        9\n",
       "Switzerland                    8\n",
       "Austria                        8\n",
       "Romania                        8\n",
       "                            ... \n",
       "Tunisia                        2\n",
       "Indonesia                      2\n",
       "Singapore                      2\n",
       "Malta                          2\n",
       "Pakistan                       2\n",
       "Serbia                         2\n",
       "Iceland                        2\n",
       "Ukraine                        2\n",
       "Qatar                          2\n",
       "Cambodia                       2\n",
       "Jordan                         1\n",
       "Ethiopia                       1\n",
       "Mongolia                       1\n",
       "Peru                           1\n",
       "Namibia                        1\n",
       "Costa Rica                     1\n",
       "Algeria                        1\n",
       "Burkina Faso                   1\n",
       "Mauritania                     1\n",
       "Uruguay                        1\n",
       "Paraguay                       1\n",
       "Serbia and Montenegro          1\n",
       "Puerto Rico                    1\n",
       "Ghana                          1\n",
       "Portugal                       1\n",
       "Croatia                        1\n",
       "Slovenia                       1\n",
       "Bosnia and Herzegovina         1\n",
       "Cyprus                         1\n",
       "Saudi Arabia                   1\n",
       "Length: 74, dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_countries_dt.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a=[]\n",
    "for item in all_countries_dt.value_counts().index[0:6]:\n",
    "    a.append(item.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['united states of america',\n",
       " 'united kingdom',\n",
       " 'france',\n",
       " 'germany',\n",
       " 'canada',\n",
       " 'india']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for item in all_countries_dt.value_counts().index[0:6]:\n",
    "    create_col(item,'production_countries')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### release_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "date = dt_train['release_date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "#dt_train['timestamp'] = datetime.strptime(dt_train['Dates'][0], '%Y-%m-%d %H:%M:%S')\n",
    "dt_train['timestamp'] = pd.DataFrame(datetime.strptime(x, '%m/%d/%y') for x in dt_train['release_date'])\n",
    "dt_train['year'] = pd.DataFrame([x.year if x.year<2019 else (x.year-100) for x in dt_train['timestamp']])\n",
    "dt_train['decade'] = pd.DataFrame(['decade '+str(int(str(x)[-2:])//10*10) for x in dt_train['year']])\n",
    "dt_train['month'] = pd.DataFrame([('month '+str(x.month)) for x in dt_train['timestamp']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "month_dummies = pd.get_dummies(dt_train['month'])\n",
    "decade_dummies = pd.get_dummies(dt_train['decade'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "runtime = dt_train ['runtime']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "run_mean = runtime.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rafael/anaconda/lib/python3.6/site-packages/pandas/core/indexing.py:190: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "for n in range(len(runtime)):\n",
    "    if math.isnan(runtime.iloc[n]):\n",
    "        runtime.iloc[n] = run_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "runtime_dt = pd.DataFrame(runtime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaler_run = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "runtime_sc = pd.DataFrame(scaler_run.fit_transform(runtime_dt)).rename(index=str, columns={0: \"runtime\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "genres = dt_train['genres']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "genres = genres.fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_genres = []\n",
    "for obs in genres:\n",
    "    if obs!='':\n",
    "        item = ast.literal_eval(obs.replace('[','').replace(']',''))\n",
    "        if type(item)==dict:\n",
    "            all_genres.append(item['name'])\n",
    "        else:\n",
    "            for c in item:\n",
    "                all_genres.append(c['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unique_genres = list(set(all_genres))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tudo isso foi feito para se identificar quais eram todos os gêneros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a=[]\n",
    "for item in unique_genres:\n",
    "      a.append(item.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for item in unique_genres:\n",
    "    create_col(item,'genres')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### spoken_languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spoken_languages = dt_train['spoken_languages']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spoken_languages = spoken_languages.fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lang_counts = []\n",
    "for obs in spoken_languages:\n",
    "    if obs!='':\n",
    "        item = ast.literal_eval(obs.replace('[','').replace(']',''))\n",
    "        if type(item)==dict:\n",
    "            lang_counts.append('L1')\n",
    "        else:\n",
    "            lang_counts.append('L2+')\n",
    "    else:\n",
    "        lang_counts.append('L1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lang_counts_dt = pd.DataFrame(lang_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lang_counts_dummies = pd.get_dummies(lang_counts_dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cast = dt_train['cast']\n",
    "cast = cast.fillna('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IDEIA: VERIFICAR QUANTAS MULHERES E HOMENS POR FILME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "first_gender = []\n",
    "n_actors = []\n",
    "#n=0\n",
    "for obs in cast:\n",
    "    if obs!='' and obs!='[]':\n",
    "        item = ast.literal_eval(obs.replace('[','').replace(']',''))\n",
    "        if type(item)==dict:\n",
    "            first_gender.append('gender '+ str(item['gender']))\n",
    "            n_actors.append(1)\n",
    "        else:\n",
    "            first_gender.append('gender '+ str(item[0]['gender']))\n",
    "            n_actors.append(len(item))\n",
    "    else:\n",
    "        first_gender.append('no_actors')\n",
    "        n_actors.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rafael/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/data.py:323: DataConversionWarning: Data with input dtype int64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "first_gender_dt = pd.DataFrame(first_gender).rename(index=str, columns={0: \"first_gender\"})\n",
    "first_gender_dummies = pd.get_dummies(first_gender)\n",
    "n_act_scaler = MinMaxScaler()\n",
    "n_actors_sc = pd.DataFrame(n_act_scaler.fit_transform(pd.DataFrame(n_actors))).rename(index=str, columns={0: \"n_actors\"})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "act_list = ['tom hanks',\n",
    "'christian bale',\n",
    "'leonardo dicaprio', \n",
    "'morgan freeman',\n",
    "'robert de niro',\n",
    "'anthony hopkins',\n",
    "'denzel washington',\n",
    "'robert downey jr',\n",
    "'kevin spacey',\n",
    "'johnny depp',\n",
    "'gary oldman',\n",
    "'daniel day-lewis',\n",
    "'edward norton',\n",
    "'al pacino',\n",
    "'liam neeson',\n",
    "'matt damon',\n",
    "'brad pitt',\n",
    "'hugh jackman',\n",
    "'jack nicholson',\n",
    "'marlon brando',\n",
    "'clint eastwood',\n",
    "'harrison ford',\n",
    "'robin williams',\n",
    "'mel gibson',\n",
    "'john travolta','meryl streep','andy serkis', 'jodie foster', 'jennifer lawrence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_col_lowercase(name,name_col):\n",
    "    dt_train[name.lower()] = dt_train[name_col].str.lower().str.contains(name, regex=False)\n",
    "    dt_train[name.lower()] = dt_train[name.lower()].apply(lambda x: 1 if x ==True else 0)\n",
    "\n",
    "for item in act_list:\n",
    "    create_col_lowercase(item, 'cast')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def index_reset(dataset):\n",
    "    dataset.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c = [budget_sc,popularity_sc,month_dummies,decade_dummies,runtime_sc,original_language_dummies,lang_counts_dummies,n_actors_sc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for item in c:\n",
    "    index_reset(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = pd.concat([budget_sc,\n",
    "                      popularity_sc,\n",
    "                      month_dummies,\n",
    "                      decade_dummies,\n",
    "                      runtime_sc,\n",
    "                      original_language_dummies,\n",
    "                      lang_counts_dummies,\n",
    "                      n_actors_sc,\n",
    "                      dt_train[['fantasy',\n",
    "                                'crime',\n",
    "                                'history',\n",
    "                                'science fiction',\n",
    "                                'action',\n",
    "                                'tv movie',\n",
    "                                'music',\n",
    "                                'western',\n",
    "                                'family',\n",
    "                                'documentary',\n",
    "                                'mystery',\n",
    "                                'thriller',\n",
    "                                'horror',\n",
    "                                'adventure',\n",
    "                                'foreign',\n",
    "                                'romance',\n",
    "                                'animation',\n",
    "                                'war',\n",
    "                                'drama',\n",
    "                                'comedy','warner bros.',\n",
    "                                'universal pictures',\n",
    "                                'paramount pictures',\n",
    "                                'twentieth century fox film corporation',\n",
    "                                'columbia pictures',\n",
    "                                'metro-goldwyn-mayer (mgm)',\n",
    "                                'new line cinema',\n",
    "                                'touchstone pictures',\n",
    "                                'walt disney pictures',\n",
    "                                'columbia pictures corporation',\n",
    "                                'united states of america',\n",
    "                                'united kingdom',\n",
    "                                'france',\n",
    "                                'germany',\n",
    "                                'canada',\n",
    "                                'india','tom hanks',\n",
    "                                'christian bale',\n",
    "                                'leonardo dicaprio', \n",
    "                                'morgan freeman',\n",
    "                                'robert de niro',\n",
    "                                'anthony hopkins',\n",
    "                                'denzel washington',\n",
    "                                'robert downey jr',\n",
    "                                'kevin spacey',\n",
    "                                'johnny depp',\n",
    "                                'gary oldman',\n",
    "                                'daniel day-lewis',\n",
    "                                'edward norton',\n",
    "                                'al pacino',\n",
    "                                'liam neeson',\n",
    "                                'matt damon',\n",
    "                                'brad pitt',\n",
    "                                'hugh jackman',\n",
    "                                'jack nicholson',\n",
    "                                'marlon brando',\n",
    "                                'clint eastwood',\n",
    "                                'harrison ford',\n",
    "                                'robin williams',\n",
    "                                'mel gibson',\n",
    "                                'john travolta',\n",
    "                                'meryl streep',\n",
    "                                'andy serkis', \n",
    "                                'jodie foster',\n",
    "                                'jennifer lawrence']]],axis=1)\n",
    "                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = pd.concat([budget_sc,\n",
    "                      popularity_sc,\n",
    "                      month_dummies,\n",
    "                      decade_dummies,\n",
    "                      runtime_sc,\n",
    "                      original_language_dummies,\n",
    "                      lang_counts_dummies,\n",
    "                      n_actors_sc,\n",
    "                      dt_train[['fantasy',\n",
    "                                'crime',\n",
    "                                'history',\n",
    "                                'science fiction',\n",
    "                                'action',\n",
    "                                'tv movie',\n",
    "                                'music',\n",
    "                                'western',\n",
    "                                'family',\n",
    "                                'documentary',\n",
    "                                'mystery',\n",
    "                                'thriller',\n",
    "                                'horror',\n",
    "                                'adventure',\n",
    "                                'foreign',\n",
    "                                'romance',\n",
    "                                'animation',\n",
    "                                'war',\n",
    "                                'drama',\n",
    "                                'comedy','warner bros.',\n",
    "                                'universal pictures',\n",
    "                                'paramount pictures',\n",
    "                                'twentieth century fox film corporation',\n",
    "                                'columbia pictures',\n",
    "                                'metro-goldwyn-mayer (mgm)',\n",
    "                                'new line cinema',\n",
    "                                'touchstone pictures',\n",
    "                                'walt disney pictures',\n",
    "                                'columbia pictures corporation',\n",
    "                                'united states of america',\n",
    "                                'united kingdom',\n",
    "                                'france',\n",
    "                                'germany',\n",
    "                                'canada',\n",
    "                                'india',\n",
    "                                'tom hanks',\n",
    "                                'christian bale',\n",
    "                                'leonardo dicaprio', \n",
    "                                'morgan freeman',\n",
    "                                'robert de niro',\n",
    "                                'anthony hopkins',\n",
    "                                'denzel washington',\n",
    "                                'robert downey jr',\n",
    "                                'kevin spacey',\n",
    "                                'johnny depp',\n",
    "                                'gary oldman',\n",
    "                                'daniel day-lewis',\n",
    "                                'edward norton',\n",
    "                                'al pacino',\n",
    "                                'liam neeson',\n",
    "                                'matt damon',\n",
    "                                'brad pitt',\n",
    "                                'hugh jackman',\n",
    "                                'jack nicholson',\n",
    "                                'marlon brando',\n",
    "                                'clint eastwood',\n",
    "                                'harrison ford',\n",
    "                                'robin williams',\n",
    "                                'mel gibson',\n",
    "                                'john travolta',\n",
    "                                'meryl streep',\n",
    "                                'andy serkis', \n",
    "                                'jodie foster', \n",
    "                                'jennifer lawrence']]],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features_fds = pd.concat([budget_sc,\n",
    "                      popularity_sc,\n",
    "                      month_dummies,\n",
    "                      decade_dummies,\n",
    "                      runtime_sc,\n",
    "                      original_language_dummies,\n",
    "                      lang_counts_dummies,\n",
    "                      n_actors_sc,\n",
    "                      dt_train[['fantasy',\n",
    "                                'crime',\n",
    "                                'history',\n",
    "                                'science fiction',\n",
    "                                'action',\n",
    "                                'tv movie',\n",
    "                                'music',\n",
    "                                'western',\n",
    "                                'family',\n",
    "                                'documentary',\n",
    "                                'mystery',\n",
    "                                'thriller',\n",
    "                                'horror',\n",
    "                                'adventure',\n",
    "                                'romance',\n",
    "                                'animation',\n",
    "                                'war',\n",
    "                                'drama',\n",
    "                                'comedy',\n",
    "                                'warner bros.',\n",
    "                                'universal pictures',\n",
    "                                'paramount pictures',\n",
    "                                'twentieth century fox film corporation',\n",
    "                                'columbia pictures',\n",
    "                                'metro-goldwyn-mayer (mgm)',\n",
    "                                'new line cinema',\n",
    "                                'touchstone pictures',\n",
    "                                'walt disney pictures',\n",
    "                                'columbia pictures corporation',\n",
    "                                'united states of america',\n",
    "                                'united kingdom',\n",
    "                                'france',\n",
    "                                'india',\n",
    "                                'tom hanks',\n",
    "                                'christian bale',\n",
    "                                'leonardo dicaprio', \n",
    "                                'morgan freeman',\n",
    "                                'robert de niro',\n",
    "                                'denzel washington',\n",
    "                                'robert downey jr',\n",
    "                                'kevin spacey',\n",
    "                                'johnny depp',\n",
    "                                'gary oldman',\n",
    "                                'daniel day-lewis',\n",
    "                                'al pacino',\n",
    "                                'liam neeson',\n",
    "                                'matt damon',\n",
    "                                'brad pitt',\n",
    "                                'hugh jackman',\n",
    "                                'jack nicholson',\n",
    "                                'marlon brando',\n",
    "                                'clint eastwood',\n",
    "                                'harrison ford',\n",
    "                                'robin williams',\n",
    "                                'mel gibson',\n",
    "                                'john travolta',\n",
    "                                'meryl streep',\n",
    "                                'andy serkis' ]]],axis=1)\n",
    "                      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "revenue = pd.DataFrame(dt_train['revenue'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "revenue.reset_index(drop=True, inplace=True)\n",
    "revenue.rename(index=str, columns={0: \"revenue\"},inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seleção de features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correlations = pd.concat([features.reset_index(drop=True),revenue.reset_index(drop=True)],axis=1).corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corr_rev = correlations.sort_values(by='revenue',ascending=False)['revenue']\n",
    "corr_rev = corr_rev[corr_rev<1]\n",
    "\n",
    "corr_p = corr_rev[(corr_rev>0)]\n",
    "corr_p = corr_p[corr_p<1]\n",
    "\n",
    "features_ord = list(corr_rev.index)\n",
    "features_best = list(corr_p.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "bestfeatures = SelectKBest(score_func=chi2, k=35)\n",
    "fit = bestfeatures.fit(features,revenue)\n",
    "dfscores = pd.DataFrame(fit.scores_)\n",
    "dfcolumns = pd.DataFrame(features.columns)\n",
    "#concat two dataframes for better visualization \n",
    "featureScores = pd.concat([dfcolumns,dfscores],axis=1)\n",
    "featureScores.columns = ['Specs','Score']  #naming the dataframe columns\n",
    "#print(featureScores.nlargest(35,'Score'))  #print 10 best features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features_best3=list(featureScores.sort_values(by='Score')['Specs'][:60])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corr_rev2 = abs(correlations).sort_values(by='revenue',ascending=False)['revenue']\n",
    "\n",
    "corr_p2 = corr_rev[corr_rev>0.04]\n",
    "features_best2 = list(corr_p2.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRAIN TEST SPLIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set has 2400 samples.\n",
      "Testing set has 600 samples.\n"
     ]
    }
   ],
   "source": [
    "# Shuffle e Split da base sem PCA\n",
    "X_train, X_test, y_train, y_test = train_test_split(features[features_best3], \n",
    "                                                    np.log(revenue['revenue']), \n",
    "                                                    test_size = 0.2, \n",
    "                                                    random_state = 19, \n",
    "                                                    shuffle=True)\n",
    "\n",
    "# Show the results of the split\n",
    "print(\"Training set has {} samples.\".format(X_train.shape[0]))\n",
    "print(\"Testing set has {} samples.\".format(X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## REGRESSORS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1846,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8571246140967187, 1.9910362458035005)"
      ]
     },
     "execution_count": 1846,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_RMSD(reg10, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1758,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "reg1 = LinearRegression()\n",
    "reg2 = LinearRegression(n_jobs=10)\n",
    "reg3 = SVR()\n",
    "reg4 = SVR(C=10)\n",
    "reg5 = SVR(kernel='poly')\n",
    "reg6 = AdaBoostRegressor(random_state=19)\n",
    "reg7 = AdaBoostRegressor(base_estimator = DecisionTreeRegressor(max_depth=10),random_state=19)\n",
    "reg8 = AdaBoostRegressor(base_estimator = DecisionTreeRegressor(max_depth=20),random_state=19)\n",
    "reg9 = AdaBoostRegressor(n_estimators = 200,base_estimator = DecisionTreeRegressor(max_depth=20),random_state=19)\n",
    "reg10 = AdaBoostRegressor(n_estimators = 200,base_estimator = DecisionTreeRegressor(max_depth=10),random_state=19)\n",
    "reg11 = AdaBoostRegressor(n_estimators = 100,base_estimator = DecisionTreeRegressor(max_depth=10),random_state=19)\n",
    "reg12 = AdaBoostRegressor(base_estimator = DecisionTreeRegressor(min_samples_split=10,max_depth=10),random_state=19)\n",
    "reg13 = AdaBoostRegressor(base_estimator = DecisionTreeRegressor(min_samples_split=9,max_depth=10),random_state=19)\n",
    "\n",
    "reg14 = RandomForestRegressor(random_state=19)\n",
    "reg15 = RandomForestRegressor(random_state=19, max_depth = 5)\n",
    "reg16 = RandomForestRegressor(random_state=19, max_depth = 10, min_samples_split = 15)\n",
    "reg17 = RandomForestRegressor(random_state=19, max_depth = 6, max_features=5)\n",
    "\n",
    "reg10b = AdaBoostRegressor(n_estimators = 200, loss='exponential',base_estimator = DecisionTreeRegressor(max_depth=10),random_state=19)\n",
    "reg10c = AdaBoostRegressor(n_estimators = 300,base_estimator = DecisionTreeRegressor(max_depth=10),random_state=19)\n",
    "reg10d = AdaBoostRegressor(n_estimators = 150,base_estimator = DecisionTreeRegressor(max_depth=10),random_state=19)\n",
    "reg10e = AdaBoostRegressor(n_estimators = 180,base_estimator = DecisionTreeRegressor(max_depth=10),random_state=19)\n",
    "reg10f = AdaBoostRegressor(n_estimators = 220,base_estimator = DecisionTreeRegressor(max_depth=10),random_state=19)\n",
    "reg10g = AdaBoostRegressor(n_estimators = 230,base_estimator = DecisionTreeRegressor(max_depth=10),random_state=19)\n",
    "\n",
    "reg18 = GradientBoostingRegressor(random_state=19)\n",
    "reg19 = GradientBoostingRegressor(random_state=19,learning_rate=.5)\n",
    "reg20 = GradientBoostingRegressor(random_state=19,learning_rate=.1)\n",
    "reg21= GradientBoostingRegressor(random_state=19,max_depth=10)\n",
    "reg22 = GradientBoostingRegressor(random_state=19,max_depth=5)\n",
    "reg23 = GradientBoostingRegressor(random_state=19, )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 893,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def RMSD(y_actual, y_pred):\n",
    "    dif2=0\n",
    "    for n in range(len(y_actual)):\n",
    "        dif2 = dif2+ (y_actual.iloc[n]-y_pred[n])**2\n",
    "    r = (dif2/len(y_actual))**(1/2)\n",
    "    return r\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 894,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_RMSD(reg, xtrain, ytrain,xtest,ytest):\n",
    "    reg.fit(xtrain,ytrain)\n",
    "    ypred_test = reg.predict(xtest)\n",
    "    ypred_train = reg.predict(xtrain)\n",
    "    rmsd_test = RMSD(ytest,ypred_test)\n",
    "    rmsd_train=RMSD(ytrain,ypred_train)\n",
    "    return rmsd_train,rmsd_test\n",
    "    print('Train RMSD: {} /n Test RMSD: {}'.format(rmsd_train, rmsd_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1847,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.4390918754731485, 2.2925108479566805)"
      ]
     },
     "execution_count": 1847,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_RMSD(reg1, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1848,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.4390918754731485, 2.2925108479566805)"
      ]
     },
     "execution_count": 1848,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_RMSD(reg2, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1849,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rafael/anaconda/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2.7380394561556627, 2.5338867559856375)"
      ]
     },
     "execution_count": 1849,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_RMSD(reg3, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1850,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rafael/anaconda/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2.5051932768802136, 2.3302978947387203)"
      ]
     },
     "execution_count": 1850,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_RMSD(reg4, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1851,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rafael/anaconda/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3.1532734828570357, 2.9708068665036165)"
      ]
     },
     "execution_count": 1851,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_RMSD(reg5, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1852,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.5609165698866203, 2.503722415034288)"
      ]
     },
     "execution_count": 1852,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_RMSD(reg6, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1853,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8860071243496803, 2.0019536508948566)"
      ]
     },
     "execution_count": 1853,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_RMSD(reg7, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1854,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.19953686349371216, 2.119650873628935)"
      ]
     },
     "execution_count": 1854,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_RMSD(reg8, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1855,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.18452457654498985, 2.0679547301294767)"
      ]
     },
     "execution_count": 1855,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_RMSD(reg9, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1856,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8571246140967187, 1.9910362458035005)"
      ]
     },
     "execution_count": 1856,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_RMSD(reg10, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1857,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8731725252599343, 2.0020013170228514)"
      ]
     },
     "execution_count": 1857,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_RMSD(reg11, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1858,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0188281810222921, 2.045496094827058)"
      ]
     },
     "execution_count": 1858,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_RMSD(reg12, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1859,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9849473169241314, 1.9772971012395641)"
      ]
     },
     "execution_count": 1859,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_RMSD(reg13, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1860,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8571246140967187, 1.9910362458035005)"
      ]
     },
     "execution_count": 1860,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_RMSD(reg10, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1861,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8516102657419777, 1.979822831677371)"
      ]
     },
     "execution_count": 1861,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_RMSD(reg10c, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1862,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8650656109584204, 1.9963558954674248)"
      ]
     },
     "execution_count": 1862,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_RMSD(reg10d, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1863,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8633527694032058, 1.9918568777371426)"
      ]
     },
     "execution_count": 1863,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_RMSD(reg10e, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1864,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8566831591881805, 1.9848679869216808)"
      ]
     },
     "execution_count": 1864,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_RMSD(reg10f, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1865,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.862859322293951, 2.0073457975824045)"
      ]
     },
     "execution_count": 1865,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_RMSD(reg18, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1866,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.3025288812920663, 2.2068759491946204)"
      ]
     },
     "execution_count": 1866,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_RMSD(reg19, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1867,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.862859322293951, 2.0073457975824045)"
      ]
     },
     "execution_count": 1867,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_RMSD(reg20, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1868,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.18186291087989723, 2.3621305703462516)"
      ]
     },
     "execution_count": 1868,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_RMSD(reg21, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1869,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.3174029807366272, 2.10872730897808)"
      ]
     },
     "execution_count": 1869,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_RMSD(reg22, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1870,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.862859322293951, 2.0073457975824045)"
      ]
     },
     "execution_count": 1870,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_RMSD(reg23, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def RMSD_grid(y_actual, y_pred):\n",
    "    dif2=0\n",
    "    for n in range(len(y_actual)):\n",
    "        dif2 = dif2+ (y_actual.iloc[n]-y_pred[n])**2\n",
    "    r = (dif2/len(y_actual))**(1/2)\n",
    "    return r\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1010,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rafael/anaconda/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV \n",
    "from  sklearn.metrics import make_scorer\n",
    "\n",
    "# TODO: Initialize the classifier\n",
    "reg = AdaBoostRegressor(random_state=19)\n",
    "\n",
    "# TODO: Create the parameters list you wish to tune, using a dictionary if needed.\n",
    "p_list = ['n_estimators','base_estimator','learning_rate']\n",
    "\n",
    "# HINT: parameters = {'parameter_1': [value1, value2], 'parameter_2': [value1, value2]}\n",
    "parameters = {'n_estimators':[10,50,100,150,200,250],\n",
    "              'learning_rate':[0.1,0.2,0.5,0.7,0.8,1],\n",
    "              'base_estimator':[DecisionTreeRegressor(max_depth=20),\n",
    "                                DecisionTreeRegressor(max_depth=15),\n",
    "                                DecisionTreeRegressor(max_depth=10),\n",
    "                                DecisionTreeRegressor(max_depth=8),\n",
    "                                DecisionTreeRegressor(max_depth=5),\n",
    "                                DecisionTreeRegressor(max_depth=3)]}\n",
    "\n",
    "# TODO: Make an fbeta_score scoring object using make_scorer()\n",
    "scorer = make_scorer(RMSD, greater_is_better=False)\n",
    "\n",
    "# TODO: Perform grid search on the classifier using 'scorer' as the scoring method using GridSearchCV()\n",
    "grid_obj = GridSearchCV(reg, parameters, scorer)\n",
    "\n",
    "# TODO: Fit the grid search object to the training data and find the optimal parameters using fit()\n",
    "grid_fit = grid_obj.fit(X_train, y_train)\n",
    "\n",
    "# Get the estimator\n",
    "best_reg = grid_fit.best_estimator_\n",
    "\n",
    "# Make predictions using the unoptimized and model\n",
    "predictions = (reg.fit(X_train, y_train)).predict(X_test)\n",
    "best_predictions = best_reg.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1012,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8778602502032161, 1.9717782005429023)"
      ]
     },
     "execution_count": 1012,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_RMSD(best_reg, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST DATA\n",
    "# TEST DATA\n",
    "# TEST DATA\n",
    "# TEST DATA\n",
    "# TEST DATA\n",
    "# TEST DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dt_test = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_col_test(name,name_col):\n",
    "    dt_test[name.lower()] = dt_test[name_col].str.contains(name, regex=False)\n",
    "    dt_test[name.lower()] = dt_test[name.lower()].apply(lambda x: 1 if x ==True else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "budget_test = pd.DataFrame(dt_test['budget'])\n",
    "budget_sc_test = pd.DataFrame(scaler_bu.transform(budget_test)).rename(index=str, columns={0: \"budget\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "original_language_test = dt_test['original_language']\n",
    "original_language_dummies_test = pd.get_dummies(original_language_test)[['en','fr','ru','es','hi']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "popularity_test = pd.DataFrame(dt_test['popularity'])\n",
    "popularity_sc_test = pd.DataFrame(scaler_pop.transform(popularity_test)).rename(index=str, columns={0: \"pop\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# companies = dt_test['production_companies']\n",
    "# companies = companies.fillna('')\n",
    "\n",
    "# all_companies = []\n",
    "# for obs in companies:\n",
    "#     if obs!='':\n",
    "#         item = ast.literal_eval(obs.replace('[','').replace(']',''))\n",
    "#         if type(item)==dict:\n",
    "#             all_companies.append(item['name'])\n",
    "#         else:\n",
    "#             for c in item:\n",
    "#                 all_companies.append(c['name'])\n",
    "\n",
    "# all_companies_dt = pd.Series(all_companies)\n",
    "\n",
    "# for item in all_companies_dt.value_counts().index[0:10]:\n",
    "#     create_col_test(item,'production_companies')\n",
    "    \n",
    "# a=[]\n",
    "# for item in all_companies_dt.value_counts().index[0:10]:\n",
    "#     a.append(item.lower())\n",
    "\n",
    "l = ['warner bros.',\n",
    " 'universal pictures',\n",
    " 'paramount pictures',\n",
    " 'twentieth century fox film corporation',\n",
    " 'columbia pictures',\n",
    " 'metro-goldwyn-mayer (mgm)',\n",
    " 'new line cinema',\n",
    " 'touchstone pictures',\n",
    " 'walt disney pictures',\n",
    " 'columbia pictures corporation']\n",
    "\n",
    "for item in l:\n",
    "    create_col_test(item,'production_companies')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# countries = dt_test['production_countries']\n",
    "# countries = production_countries.fillna('')\n",
    "\n",
    "# all_countries = []\n",
    "# for obs in countries:\n",
    "#     if obs!='':\n",
    "#         item = ast.literal_eval(obs.replace('[','').replace(']',''))\n",
    "#         if type(item)==dict:\n",
    "#             all_countries.append(item['name'])\n",
    "#         else:\n",
    "#             for c in item:\n",
    "#                 all_countries.append(c['name'])\n",
    "\n",
    "# all_countries_dt = pd.Series(all_countries)\n",
    "\n",
    "# b=[]\n",
    "# for item in all_countries_dt.value_counts().index[0:6]:\n",
    "#     b.append(item.lower())\n",
    "\n",
    "l = ['united states of america',\n",
    " 'united kingdom',\n",
    " 'france',\n",
    " 'germany',\n",
    " 'canada',\n",
    " 'india']\n",
    "\n",
    "for item in l:\n",
    "    create_col_test(item,'production_countries')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rafael/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "date_test = dt_test['release_date']\n",
    "date_test[828]='5/10/00'\n",
    "from datetime import datetime\n",
    "\n",
    "dt_test['timestamp'] = pd.DataFrame(datetime.strptime(x, '%m/%d/%y') for x in dt_test['release_date'])\n",
    "dt_test['year'] = pd.DataFrame([x.year if x.year<2019 else (x.year-100) for x in dt_test['timestamp']])\n",
    "dt_test['decade'] = pd.DataFrame(['decade '+str(int(str(x)[-2:])//10*10) for x in dt_test['year']])\n",
    "dt_test['month'] = pd.DataFrame([('month '+str(x.month)) for x in dt_test['timestamp']])\n",
    "\n",
    "month_dummies_test = pd.get_dummies(dt_test['month'])\n",
    "decade_dummies_test = pd.get_dummies(dt_test['decade'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rafael/anaconda/lib/python3.6/site-packages/pandas/core/indexing.py:190: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "runtime_test = dt_test['runtime']\n",
    "\n",
    "for n in range(len(runtime_test)):\n",
    "    if math.isnan(runtime_test.iloc[n]):\n",
    "        runtime_test.iloc[n] = run_mean\n",
    "\n",
    "runtime_dt_test = pd.DataFrame(runtime_test)\n",
    "runtime_sc_test = pd.DataFrame(scaler_run.transform(runtime_dt_test)).rename(index=str, columns={0: \"runtime\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "genres_test = dt_test['genres']\n",
    "genres_test = genres_test.fillna('')\n",
    "\n",
    "for item in unique_genres:\n",
    "    create_col_test(item,'genres')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spoken_languages_test = dt_test['spoken_languages']\n",
    "spoken_languages_test = spoken_languages_test.fillna('')\n",
    "\n",
    "lang_counts_test = []\n",
    "for obs in spoken_languages_test:\n",
    "    if obs!='':\n",
    "        item = ast.literal_eval(obs.replace('[','').replace(']',''))\n",
    "        if type(item)==dict:\n",
    "            lang_counts_test.append('L1')\n",
    "        else:\n",
    "            lang_counts_test.append('L2+')\n",
    "    else:\n",
    "        lang_counts_test.append('L1')\n",
    "\n",
    "lang_counts_dt_test = pd.DataFrame(lang_counts_test)\n",
    "lang_counts_dummies_test = pd.get_dummies(lang_counts_dt_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cast_test = dt_test['cast']\n",
    "cast_test = cast_test.fillna('')\n",
    "\n",
    "first_gender_test = []\n",
    "n_actors_test = []\n",
    "#n=0\n",
    "for obs in cast_test:\n",
    "    if obs!='' and obs!='[]':\n",
    "        item = ast.literal_eval(obs.replace('[','').replace(']',''))\n",
    "        if type(item)==dict:\n",
    "            first_gender_test.append('gender '+ str(item['gender']))\n",
    "            n_actors_test.append(1)\n",
    "        else:\n",
    "            first_gender_test.append('gender '+ str(item[0]['gender']))\n",
    "            n_actors_test.append(len(item))\n",
    "    else:\n",
    "        first_gender_test.append('no_actors')\n",
    "        n_actors_test.append(0)\n",
    "\n",
    "first_gender_dt_test = pd.DataFrame(first_gender_test).rename(index=str, columns={0: \"first_gender\"})\n",
    "first_gender_dummies_test = pd.get_dummies(first_gender_test)\n",
    "n_actors_sc_test = pd.DataFrame(n_act_scaler.transform(pd.DataFrame(n_actors_test))).rename(index=str, columns={0: \"n_actors\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c = [budget_sc_test,\n",
    "     popularity_sc_test,\n",
    "     month_dummies_test,\n",
    "     decade_dummies_test,\n",
    "     runtime_sc_test,\n",
    "     original_language_dummies_test,\n",
    "     lang_counts_dummies_test,\n",
    "     n_actors_sc_test]\n",
    "for item in c:\n",
    "    index_reset(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_col_lowercase_test(name,name_col):\n",
    "    dt_test[name.lower()] = dt_test[name_col].str.lower().str.contains(name, regex=False)\n",
    "    dt_test[name.lower()] = dt_test[name.lower()].apply(lambda x: 1 if x ==True else 0)\n",
    "\n",
    "for item in act_list:\n",
    "    create_col_lowercase_test(item, 'cast')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features_test = pd.concat([budget_sc_test,\n",
    "                      popularity_sc_test,\n",
    "                      month_dummies_test,\n",
    "                      decade_dummies_test,\n",
    "                      runtime_sc_test,\n",
    "                      original_language_dummies_test,\n",
    "                      lang_counts_dummies_test,\n",
    "                      n_actors_sc_test,\n",
    "                      dt_test[['fantasy',\n",
    "                                'crime',\n",
    "                                'history',\n",
    "                                'science fiction',\n",
    "                                'action',\n",
    "                                'tv movie',\n",
    "                                'music',\n",
    "                                'western',\n",
    "                                'family',\n",
    "                                'documentary',\n",
    "                                'mystery',\n",
    "                                'thriller',\n",
    "                                'horror',\n",
    "                                'adventure',\n",
    "                                'foreign',\n",
    "                                'romance',\n",
    "                                'animation',\n",
    "                                'war',\n",
    "                                'drama',\n",
    "                                'comedy','warner bros.',\n",
    "                                'universal pictures',\n",
    "                                'paramount pictures',\n",
    "                                'twentieth century fox film corporation',\n",
    "                                'columbia pictures',\n",
    "                                'metro-goldwyn-mayer (mgm)',\n",
    "                                'new line cinema',\n",
    "                                'touchstone pictures',\n",
    "                                'walt disney pictures',\n",
    "                                'columbia pictures corporation',\n",
    "                                'united states of america',\n",
    "                                'united kingdom',\n",
    "                                'france',\n",
    "                                'germany',\n",
    "                                'canada',\n",
    "                                'india',\n",
    "                                'tom hanks',\n",
    "                                'christian bale',\n",
    "                                'leonardo dicaprio', \n",
    "                                'morgan freeman',\n",
    "                                'robert de niro',\n",
    "                                'anthony hopkins',\n",
    "                                'denzel washington',\n",
    "                                'robert downey jr',\n",
    "                                'kevin spacey',\n",
    "                                'johnny depp',\n",
    "                                'gary oldman',\n",
    "                                'daniel day-lewis',\n",
    "                                'edward norton',\n",
    "                                'al pacino',\n",
    "                                'liam neeson',\n",
    "                                'matt damon',\n",
    "                                'brad pitt',\n",
    "                                'hugh jackman',\n",
    "                                'jack nicholson',\n",
    "                                'marlon brando',\n",
    "                                'clint eastwood',\n",
    "                                'harrison ford',\n",
    "                                'robin williams',\n",
    "                                'mel gibson',\n",
    "                                'john travolta',\n",
    "                                'meryl streep',\n",
    "                                'andy serkis', \n",
    "                                'jodie foster', \n",
    "                                'jennifer lawrence']]],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'reg10' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-112-be671241b50d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_pred_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreg10\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'reg10' is not defined"
     ]
    }
   ],
   "source": [
    "y_pred_test = reg10.predict(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred_f = []\n",
    "for item in y_pred_test:\n",
    "    y_pred_f.append(math.exp(item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred_test_dt = pd.DataFrame(y_pred_f).rename(index=str, columns={0: \"revenue\"})\n",
    "y_pred_test_dt.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "id_ = pd.DataFrame(dt_test['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "id_.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_final = pd.DataFrame(pd.concat([id_,y_pred_test_dt],axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_final.to_csv('pred.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBOST TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features_best0=list(featureScores.sort_values(by='Score')['Specs'][:60])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "train = pd.concat([features[features_best0].reset_index(drop=True), revenue.reset_index(drop=True)],axis=1)\n",
    "\n",
    "random_seed = 314\n",
    "k = 5\n",
    "fold = KFold(k, shuffle = True, random_state = random_seed).split(train)\n",
    "np.random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fold_list = list(fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_list = []\n",
    "test_list = []\n",
    "for n in range(len(fold_list)):\n",
    "    fold_n = fold_list[n]\n",
    "    fold_train = fold_n[0]\n",
    "    fold_test = fold_n[1]\n",
    "    train_list.append(fold_train)\n",
    "    test_list.append(fold_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {'objective': 'reg:linear', \n",
    "           'eta': 0.01, \n",
    "          'max_depth': 6, \n",
    "          'subsample': 0.7, \n",
    "          'colsample_bytree': 0.9,  \n",
    "          'eval_metric': 'rmse', \n",
    "          'seed': 5, \n",
    "          'silent': True}\n",
    "\n",
    "def fit_xgb_kfold(kfold_list, features_, revenue_train, features_pred, xgb_params):\n",
    "    train_list=[]\n",
    "    test_list=[]\n",
    "    # cria lista de indexes dos subsets de treino e validação\n",
    "    for n in range(len(kfold_list)):\n",
    "        fold_n = fold_list[n]\n",
    "        fold_train = fold_n[0]\n",
    "        fold_test = fold_n[1]\n",
    "        train_list.append(fold_train)\n",
    "        test_list.append(fold_test)\n",
    "    \n",
    "    # split para cada um dos Kfolds\n",
    "    pred_list = []\n",
    "    for n in range(len(train_list)):\n",
    "        X_train_kfold = features_.loc[train_list[n],:]\n",
    "        X_test_kfold = features_.loc[test_list[n],:]\n",
    "        y_train_kfold = np.log(revenue['revenue'].iloc[train_list[n]])\n",
    "        y_test_kfold = np.log(revenue['revenue'].iloc[test_list[n]])\n",
    "        \n",
    "        # sets para xgb\n",
    "        xgbset = [(xgb.DMatrix(X_train_kfold, y_train_kfold), 'train'), (xgb.DMatrix(X_test_kfold, y_test_kfold), 'valid')]\n",
    "        # modelo xgb\n",
    "        model = xgb.train(xgb_params, xgb.DMatrix(X_train_kfold, y_train_kfold), 2500,  xgbset, verbose_eval=100, early_stopping_rounds=200)\n",
    "        \n",
    "        # predição de saída\n",
    "        pred = np.expm1(model.predict(xgb.DMatrix(features_pred), ntree_limit=model.best_ntree_limit))\n",
    "        \n",
    "        # lista de predições\n",
    "        pred_list.append(pred)\n",
    "    \n",
    "    # média dos valores previstos\n",
    "    pred_sum = pred_list[0]*0\n",
    "    for n in range(len(pred_list)):\n",
    "        pred_sum += pred_list[n]\n",
    "    \n",
    "    # predição final\n",
    "    pred_final = pred_sum/len(pred_list)\n",
    "    \n",
    "    return pred_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-rmse:15.6288\tvalid-rmse:15.5264\n",
      "Multiple eval metrics have been passed: 'valid-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid-rmse hasn't improved in 200 rounds.\n",
      "[100]\ttrain-rmse:6.06405\tvalid-rmse:6.11464\n",
      "[200]\ttrain-rmse:2.80473\tvalid-rmse:3.08175\n",
      "[300]\ttrain-rmse:1.85954\tvalid-rmse:2.33899\n",
      "[400]\ttrain-rmse:1.58991\tvalid-rmse:2.1878\n",
      "[500]\ttrain-rmse:1.4744\tvalid-rmse:2.15624\n",
      "[600]\ttrain-rmse:1.38593\tvalid-rmse:2.14815\n",
      "[700]\ttrain-rmse:1.30791\tvalid-rmse:2.14323\n",
      "[800]\ttrain-rmse:1.2379\tvalid-rmse:2.14672\n",
      "Stopping. Best iteration:\n",
      "[690]\ttrain-rmse:1.31523\tvalid-rmse:2.14219\n",
      "\n",
      "[0]\ttrain-rmse:15.6059\tvalid-rmse:15.6201\n",
      "Multiple eval metrics have been passed: 'valid-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid-rmse hasn't improved in 200 rounds.\n",
      "[100]\ttrain-rmse:6.04274\tvalid-rmse:6.12695\n",
      "[200]\ttrain-rmse:2.75521\tvalid-rmse:3.08997\n",
      "[300]\ttrain-rmse:1.79427\tvalid-rmse:2.39271\n",
      "[400]\ttrain-rmse:1.52911\tvalid-rmse:2.28292\n",
      "[500]\ttrain-rmse:1.42249\tvalid-rmse:2.26958\n",
      "[600]\ttrain-rmse:1.34392\tvalid-rmse:2.27153\n",
      "Stopping. Best iteration:\n",
      "[499]\ttrain-rmse:1.42368\tvalid-rmse:2.26926\n",
      "\n",
      "[0]\ttrain-rmse:15.5885\tvalid-rmse:15.6896\n",
      "Multiple eval metrics have been passed: 'valid-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid-rmse hasn't improved in 200 rounds.\n",
      "[100]\ttrain-rmse:6.05521\tvalid-rmse:6.1328\n",
      "[200]\ttrain-rmse:2.80294\tvalid-rmse:2.97142\n",
      "[300]\ttrain-rmse:1.86417\tvalid-rmse:2.16662\n",
      "[400]\ttrain-rmse:1.61028\tvalid-rmse:2.00368\n",
      "[500]\ttrain-rmse:1.50073\tvalid-rmse:1.97301\n",
      "[600]\ttrain-rmse:1.41589\tvalid-rmse:1.95851\n",
      "[700]\ttrain-rmse:1.34103\tvalid-rmse:1.9488\n",
      "[800]\ttrain-rmse:1.27184\tvalid-rmse:1.94811\n",
      "[900]\ttrain-rmse:1.21186\tvalid-rmse:1.94673\n",
      "[1000]\ttrain-rmse:1.15517\tvalid-rmse:1.94945\n",
      "Stopping. Best iteration:\n",
      "[836]\ttrain-rmse:1.2493\tvalid-rmse:1.94579\n",
      "\n",
      "[0]\ttrain-rmse:15.6278\tvalid-rmse:15.5332\n",
      "Multiple eval metrics have been passed: 'valid-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid-rmse hasn't improved in 200 rounds.\n",
      "[100]\ttrain-rmse:6.05391\tvalid-rmse:6.12707\n",
      "[200]\ttrain-rmse:2.77095\tvalid-rmse:3.13942\n",
      "[300]\ttrain-rmse:1.79888\tvalid-rmse:2.43993\n",
      "[400]\ttrain-rmse:1.52264\tvalid-rmse:2.31243\n",
      "[500]\ttrain-rmse:1.40851\tvalid-rmse:2.28578\n",
      "[600]\ttrain-rmse:1.32659\tvalid-rmse:2.27455\n",
      "[700]\ttrain-rmse:1.25448\tvalid-rmse:2.26907\n",
      "[800]\ttrain-rmse:1.1884\tvalid-rmse:2.26612\n",
      "[900]\ttrain-rmse:1.13267\tvalid-rmse:2.26503\n",
      "[1000]\ttrain-rmse:1.07431\tvalid-rmse:2.26585\n",
      "Stopping. Best iteration:\n",
      "[855]\ttrain-rmse:1.15759\tvalid-rmse:2.26312\n",
      "\n",
      "[0]\ttrain-rmse:15.5921\tvalid-rmse:15.6743\n",
      "Multiple eval metrics have been passed: 'valid-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid-rmse hasn't improved in 200 rounds.\n",
      "[100]\ttrain-rmse:6.04968\tvalid-rmse:6.13454\n",
      "[200]\ttrain-rmse:2.79822\tvalid-rmse:2.99498\n",
      "[300]\ttrain-rmse:1.8423\tvalid-rmse:2.20449\n",
      "[400]\ttrain-rmse:1.57443\tvalid-rmse:2.05108\n",
      "[500]\ttrain-rmse:1.45731\tvalid-rmse:2.02173\n",
      "[600]\ttrain-rmse:1.37792\tvalid-rmse:2.01661\n",
      "[700]\ttrain-rmse:1.30516\tvalid-rmse:2.01418\n",
      "[800]\ttrain-rmse:1.23853\tvalid-rmse:2.01708\n",
      "[900]\ttrain-rmse:1.17395\tvalid-rmse:2.01882\n",
      "Stopping. Best iteration:\n",
      "[701]\ttrain-rmse:1.3039\tvalid-rmse:2.01378\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_final = fit_xgb_kfold(fold_list, \n",
    "                           features[features_best0], \n",
    "                           revenue, \n",
    "                           features_test[features_best0],  \n",
    "                           params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5700326.5,  1243233.9,  5438152.5, ..., 35154024. ,  3497775.2,\n",
       "        1034939. ], dtype=float32)"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "id_ = pd.DataFrame(dt_test['id'])\n",
    "id_.reset_index(drop=True,inplace=True)\n",
    "\n",
    "pred_xgb_dt = pd.DataFrame(pred_final)\n",
    "pred_xgb_dt.reset_index(drop=True,inplace=True)\n",
    "pred_xgb_dt = pd.DataFrame(pd.concat([id_,pred_xgb_dt],axis=1))\n",
    "pred_xgb_dt.rename(index=str, columns={0: \"revenue\"},inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_xgb_dt.to_csv('pred_xgb8.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# params = {'objective': 'reg:linear', \n",
    "#            'eta': 0.01, \n",
    "#           'max_depth': 6, \n",
    "#           'subsample': 0.7, \n",
    "#           'colsample_bytree': 0.6,  \n",
    "#           'eval_metric': 'rmse', \n",
    "#           'seed': 5, \n",
    "#           'silent': True}\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(features[features_best3], \n",
    "#                                                     np.log(revenue['revenue']), \n",
    "#                                                     test_size = 0.1, \n",
    "#                                                     random_state = 19, \n",
    "#                                                     shuffle=True)\n",
    "\n",
    "# xgbset = [(xgb.DMatrix(X_train, y_train), 'train'), (xgb.DMatrix(X_test, y_test), 'valid')]\n",
    "# model = xgb.train(params, xgb.DMatrix(X_train, y_train), 2500,  xgbset, verbose_eval=100, early_stopping_rounds=200)\n",
    "# pred_1 = np.expm1(model.predict(xgb.DMatrix(features_test_xgb), ntree_limit=model.best_ntree_limit))\n",
    "\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(features[features_best3], \n",
    "#                                                     np.log(revenue['revenue']), \n",
    "#                                                     test_size = 0.1, \n",
    "#                                                     random_state = 191, \n",
    "#                                                     shuffle=True)\n",
    "\n",
    "# xgbset = [(xgb.DMatrix(X_train, y_train), 'train'), (xgb.DMatrix(X_test, y_test), 'valid')]\n",
    "# model = xgb.train(params, xgb.DMatrix(X_train, y_train), 2500,  xgbset, verbose_eval=100, early_stopping_rounds=200)\n",
    "# pred_2 = np.expm1(model.predict(xgb.DMatrix(features_test_xgb), ntree_limit=model.best_ntree_limit))\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(features[features_best3], \n",
    "#                                                     np.log(revenue['revenue']), \n",
    "#                                                     test_size = 0.1, \n",
    "#                                                     random_state = 91, \n",
    "#                                                     shuffle=True)\n",
    "\n",
    "# xgbset = [(xgb.DMatrix(X_train, y_train), 'train'), (xgb.DMatrix(X_test, y_test), 'valid')]\n",
    "# model = xgb.train(params, xgb.DMatrix(X_train, y_train), 2500,  xgbset, verbose_eval=100, early_stopping_rounds=200)\n",
    "# pred_3 = np.expm1(model.predict(xgb.DMatrix(features_test_xgb), ntree_limit=model.best_ntree_limit))\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(features[features_best3], \n",
    "#                                                     np.log(revenue['revenue']), \n",
    "#                                                     test_size = 0.1, \n",
    "#                                                     random_state = 1, \n",
    "#                                                     shuffle=True)\n",
    "\n",
    "# xgbset = [(xgb.DMatrix(X_train, y_train), 'train'), (xgb.DMatrix(X_test, y_test), 'valid')]\n",
    "# model = xgb.train(params, xgb.DMatrix(X_train, y_train), 2500,  xgbset, verbose_eval=100, early_stopping_rounds=200)\n",
    "# pred_4 = np.expm1(model.predict(xgb.DMatrix(features_test_xgb), ntree_limit=model.best_ntree_limit))\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(features[features_best3], \n",
    "#                                                     np.log(revenue['revenue']), \n",
    "#                                                     test_size = 0.1, \n",
    "#                                                     random_state = 10, \n",
    "#                                                     shuffle=True)\n",
    "\n",
    "# xgbset = [(xgb.DMatrix(X_train, y_train), 'train'), (xgb.DMatrix(X_test, y_test), 'valid')]\n",
    "# model = xgb.train(params, xgb.DMatrix(X_train, y_train), 2500,  xgbset, verbose_eval=100, early_stopping_rounds=200)\n",
    "# pred_5 = np.expm1(model.predict(xgb.DMatrix(features_test_xgb), ntree_limit=model.best_ntree_limit))\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(features[features_best3], \n",
    "#                                                     np.log(revenue['revenue']), \n",
    "#                                                     test_size = 0.1, \n",
    "#                                                     random_state = 11, \n",
    "#                                                     shuffle=True)\n",
    "\n",
    "# xgbset = [(xgb.DMatrix(X_train, y_train), 'train'), (xgb.DMatrix(X_test, y_test), 'valid')]\n",
    "# model = xgb.train(params, xgb.DMatrix(X_train, y_train), 2500,  xgbset, verbose_eval=100, early_stopping_rounds=200)\n",
    "# pred_6 = np.expm1(model.predict(xgb.DMatrix(features_test_xgb), ntree_limit=model.best_ntree_limit))\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(features[features_best3], \n",
    "#                                                     np.log(revenue['revenue']), \n",
    "#                                                     test_size = 0.1, \n",
    "#                                                     random_state = 121, \n",
    "#                                                     shuffle=True)\n",
    "\n",
    "# xgbset = [(xgb.DMatrix(X_train, y_train), 'train'), (xgb.DMatrix(X_test, y_test), 'valid')]\n",
    "# model = xgb.train(params, xgb.DMatrix(X_train, y_train), 2500,  xgbset, verbose_eval=100, early_stopping_rounds=200)\n",
    "# pred_7 = np.expm1(model.predict(xgb.DMatrix(features_test_xgb), ntree_limit=model.best_ntree_limit))\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(features[features_best3], \n",
    "#                                                     np.log(revenue['revenue']), \n",
    "#                                                     test_size = 0.1, \n",
    "#                                                     random_state = 123, \n",
    "#                                                     shuffle=True)\n",
    "\n",
    "# xgbset = [(xgb.DMatrix(X_train, y_train), 'train'), (xgb.DMatrix(X_test, y_test), 'valid')]\n",
    "# model = xgb.train(params, xgb.DMatrix(X_train, y_train), 2500,  xgbset, verbose_eval=100, early_stopping_rounds=200)\n",
    "# pred_8 = np.expm1(model.predict(xgb.DMatrix(features_test_xgb), ntree_limit=model.best_ntree_limit))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
